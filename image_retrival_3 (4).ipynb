{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This file take random \"N\" number of query and and relevant images will from that random query class, \n",
        "# Only we need to give the databse path\n",
        "# And hyperparameter"
      ],
      "metadata": {
        "id": "Ky_3kfo9AvK5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PJTgoqAu9IsL",
        "outputId": "96ed16d4-5a27-42ed-ee7f-d35033b3a06e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "0znW3nPVj7gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53de0c1f-1c62-4861-ae93-f8221603a864"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "MsUUN6vmkCHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21354e9-e78f-4230-fb31-c7a87abf269c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "DGn_alwNkGtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf00353a-0a5e-4d98-8f3a-6a31b0cc80cc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend==0.17.0"
      ],
      "metadata": {
        "id": "5-dWIpXIkh4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cce888e-dd20-4615-db46-db72296d6301"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend==0.17.0 in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (3.7.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from mlxtend==0.17.0) (67.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->mlxtend==0.17.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.2->mlxtend==0.17.0) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.3->mlxtend==0.17.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend==0.17.0) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas"
      ],
      "metadata": {
        "id": "waO9A1x0kl3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49308aa6-8a4b-4693-eb19-74dcc8bdc9e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image"
      ],
      "metadata": {
        "id": "2TQi6rzokzJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84224a5a-dbea-41d5-a082-63d24a8e7f36"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "from torchvision.models import vgg16\n",
        "import glob\n",
        "import torch.nn as nn\n",
        "from skimage import measure\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n"
      ],
      "metadata": {
        "id": "z2Ne630cBVRU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper_parameter\n",
        "\n",
        "no_random_images = 10 # random number of images N\n",
        "\n",
        "top_no_image_print = 36  # What number of top images to be shown in image, Note it should be less than K\n",
        "\n",
        "alpha = 0.1 # α is used for balancing the effect of global and local features, Range - {0, 0.01, 0.1, · · · , 100}\n",
        "\n",
        "k = 15 # Get top K images\n",
        "\n",
        "minsupp = 2 # minimum support threshold for FPM, The range of minsupp are {0, 1, 2, · · · , 10}"
      ],
      "metadata": {
        "id": "3LKlXxlp8FKN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define paths  database image folders\n",
        "database_image_folder = r\"/content/drive/MyDrive/Colab Notebooks/database_new_new\"\n"
      ],
      "metadata": {
        "id": "OtqzknyYBjuh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class GlobalFeature:\n",
        "    def __init__(self, vgg16):\n",
        "        self.vgg16 = vgg16\n",
        "\n",
        "    def extract(self, image):\n",
        "        with torch.no_grad():\n",
        "            features = self.vgg16.features(image)\n",
        "\n",
        "        # Obtain the salient object by performing a mask operation\n",
        "        features = features.squeeze(0)\n",
        "        A = features.sum(dim=0)\n",
        "        threshold = A.mean()\n",
        "        mask = (A > threshold).float()\n",
        "\n",
        "        # Retain the largest connected component using the flood fill algorithm\n",
        "        labels = measure.label(mask.cpu().numpy())\n",
        "        largest_label = labels.max()\n",
        "        if largest_label > 0:\n",
        "            largest_area = 0\n",
        "            for i in range(1, largest_label + 1):\n",
        "                area = (labels == i).sum()\n",
        "                if area > largest_area:\n",
        "                    largest_area = area\n",
        "                    largest_component = i\n",
        "\n",
        "        for i in range(mask.shape[0]):\n",
        "            for j in range(mask.shape[1]):\n",
        "                if labels[i, j] != largest_component:\n",
        "                    mask[i, j] = 0\n",
        "\n",
        "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
        "        salient_object = features * mask\n",
        "\n",
        "        # Extract the global feature fG from the salient object\n",
        "        fG_max_pooling = nn.functional.adaptive_max_pool2d(salient_object, (1, 1)).view(-1)\n",
        "        fG_avg_pooling = nn.functional.adaptive_avg_pool2d(salient_object, (1, 1)).view(-1)\n",
        "        fG = torch.cat((fG_max_pooling, fG_avg_pooling), dim=0)\n",
        "\n",
        "        return fG"
      ],
      "metadata": {
        "id": "a7o80s4Ejkmf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class LocalFeature:\n",
        "    def __init__(self, vgg16):\n",
        "        self.vgg16 = vgg16\n",
        "\n",
        "    def extract(self, image):\n",
        "        with torch.no_grad():\n",
        "            features = self.vgg16.features(image)\n",
        "\n",
        "        # Obtain the salient object by performing a mask operation\n",
        "        features = features.squeeze(0)\n",
        "        A = features.sum(dim=0)\n",
        "        threshold = A.mean()\n",
        "        mask = (A > threshold).float()\n",
        "        mask = mask.unsqueeze(0).unsqueeze(0)\n",
        "        salient_object = features * mask\n",
        "        salient_object = salient_object.squeeze(0)\n",
        "\n",
        "        # Convert feature maps and activated positions into transactions and items\n",
        "        transactions = []\n",
        "        for i in range(salient_object.shape[0]):\n",
        "            feature_map = salient_object[i]\n",
        "            activated_positions = (feature_map > 0).nonzero(as_tuple=True)\n",
        "            items = [f'({x},{y})' for x, y in zip(*activated_positions)]\n",
        "            transactions.append(items)\n",
        "\n",
        "        # Mine frequent patterns using FPM\n",
        "        \n",
        "        I = sorted(set(item for transaction in transactions for item in transaction))\n",
        "        df = pd.DataFrame([[int(item in transaction) for item in I] for transaction in transactions], columns=I)\n",
        "        frequent_itemsets = fpgrowth(df, min_support=minsupp/len(transactions), use_colnames=True)\n",
        "\n",
        "        # Extract the local feature fL from the frequent patterns\n",
        "        patterns = torch.zeros_like(salient_object)\n",
        "        for itemset in frequent_itemsets['itemsets']:\n",
        "            for item in itemset:\n",
        "                x, y = map(int, item.strip('()').split(','))\n",
        "                patterns[:, x, y] = 1\n",
        "\n",
        "        fL_max_pooling = nn.functional.adaptive_max_pool2d(patterns, (1, 1)).view(-1)\n",
        "        fL_avg_pooling = nn.functional.adaptive_avg_pool2d(patterns, (1, 1)).view(-1)\n",
        "        fL = torch.cat((fL_max_pooling, fL_avg_pooling), dim=0)\n",
        "\n",
        "        return fL"
      ],
      "metadata": {
        "id": "mR3iarhnjsF7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_score(feature1, feature2):\n",
        "    score = torch.dot(feature1, feature2) / (torch.norm(feature1) * torch.norm(feature2))\n",
        "    return score.item()"
      ],
      "metadata": {
        "id": "qmoiV65A6Jkc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_precision(retrieved_items, relevant_items):\n",
        "    rel_count = 0\n",
        "    precisions = []\n",
        "\n",
        "    for i, item in enumerate(retrieved_items, start=1):\n",
        "        if item in relevant_items:\n",
        "            rel_count += 1\n",
        "            precision_at_i = rel_count / i\n",
        "            precisions.append(precision_at_i)\n",
        "\n",
        "    if precisions:\n",
        "        avg_precision = sum(precisions) / len(precisions)\n",
        "    else:\n",
        "        avg_precision = 0.0\n",
        "\n",
        "    return avg_precision"
      ],
      "metadata": {
        "id": "zJ4om6Bz6LuW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_recall(retrieved_items, relevant_items):\n",
        "    rel_count = 0\n",
        "    recalls = []\n",
        "\n",
        "    for i, item in enumerate(retrieved_items, start=1):\n",
        "        if item in relevant_items:\n",
        "            rel_count += 1\n",
        "            recall_at_i = rel_count / len(relevant_items)\n",
        "            recalls.append(recall_at_i)\n",
        "\n",
        "    if recalls:\n",
        "        avg_recall = sum(recalls) / len(recalls)\n",
        "    else:\n",
        "        avg_recall = 0.0\n",
        "\n",
        "    return avg_recall"
      ],
      "metadata": {
        "id": "ZIp7SYz7ttRI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_precision_recall_curve(retrieved_items, relevant_items):\n",
        "    avg_precisions = []\n",
        "    avg_recalls = []\n",
        "\n",
        "    for i in range(1, len(retrieved_items) + 1):\n",
        "        avg_precisions.append(average_precision(retrieved_items[:i], relevant_items))\n",
        "        avg_recalls.append(average_recall(retrieved_items[:i], relevant_items))\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(avg_recalls, avg_precisions, marker='o')\n",
        "    plt.xlabel('Average Recall')\n",
        "    plt.ylabel('Average Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1QnOFgqstw5n"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_roc_curve(retrieved_items, relevant_items):\n",
        "    # creating binary labels for our items\n",
        "    y_true = [1 if item in relevant_items else 0 for item in retrieved_items]\n",
        "\n",
        "    # for an ROC curve, we need scores rather than binary predictions, \n",
        "    # let's assume the score is simply the reverse rank of the item in the retrieved list\n",
        "    y_scores = [len(retrieved_items) - i for i in range(len(retrieved_items))]\n",
        "\n",
        "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_scores)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jBxZP2VAtziX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def anmrr(retrieved_items, relevant_items):\n",
        "    max_r = len(retrieved_items)\n",
        "    ideal_order = sorted(relevant_items, key=lambda x: retrieved_items.index(x) if x in retrieved_items else float('inf'))\n",
        "    sum_r = 0\n",
        "    for item in relevant_items:\n",
        "        r = retrieved_items.index(item) + 1 if item in retrieved_items else max_r\n",
        "        sum_r += min(r, max_r)\n",
        "    avg_r = sum_r / len(relevant_items)\n",
        "    sum_ideal_r = sum((i+1) for i, _ in enumerate(ideal_order))\n",
        "    avg_ideal_r = sum_ideal_r / len(relevant_items)\n",
        "    anmrr = (avg_r - avg_ideal_r) / max_r\n",
        "    return anmrr\n",
        "\n",
        "def plot_anmrr_curve(retrieved_items, relevant_items):\n",
        "    anmrr_values = []\n",
        "\n",
        "    for i in range(1, len(retrieved_items) + 1):\n",
        "        anmrr_values.append(anmrr(retrieved_items[:i], relevant_items))\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(range(1, len(retrieved_items) + 1), anmrr_values, marker='o')\n",
        "    plt.xlabel('Number of Retrieved Items')\n",
        "    plt.ylabel('ANMRR')\n",
        "    plt.title('ANMRR Curve')\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "5zeGZ1e8t1n1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(ap_scores):\n",
        "    map_score = sum(ap_scores) / len(ap_scores)\n",
        "    return map_score"
      ],
      "metadata": {
        "id": "wgHML0Pc6PtA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = vgg16(pretrained=True)\n"
      ],
      "metadata": {
        "id": "rUfO1i7F6lhy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bfae3c-fd0d-4dde-8e1b-98cca65e6d9d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB') if image.mode != 'RGB' else image),\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "QCFjsymQ6fNI"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_and_transform_images(database_image_folder, transform):\n",
        "    # Define image extensions\n",
        "    image_extensions = ['jpg', 'png', 'jpeg']\n",
        "\n",
        "    database_filenames = []\n",
        "    database_images = []\n",
        "    database_file_path = []\n",
        "\n",
        "    # Iterate over all subdirectories and files in the root directory\n",
        "    for subdir, dirs, files in os.walk(database_image_folder):\n",
        "        for filename in files:\n",
        "            # Check if the file is an image\n",
        "            if filename.split('.')[-1].lower() in image_extensions:\n",
        "                # Append the filename to the filenames list\n",
        "                database_filenames.append(filename)\n",
        "                # Open and transform the image, then append it to the images list\n",
        "                file_path = os.path.join(subdir, filename)\n",
        "                database_file_path.append(file_path)\n",
        "                with Image.open(os.path.join(subdir, filename)) as image:\n",
        "                    try:\n",
        "                        tensor_image = transform(image)\n",
        "                        database_images.append(tensor_image)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error transforming image {filename}: {str(e)}\")\n",
        "\n",
        "    # Convert the list of images into a torch tensor\n",
        "    try:\n",
        "        database_images = torch.stack(database_images)\n",
        "    except Exception as e:\n",
        "        print(f\"Error in stacking images: {str(e)}\")\n",
        "\n",
        "    return database_filenames, database_images, database_file_path\n",
        "\n",
        "database_filenames, database_images, database_file_path  = load_and_transform_images(database_image_folder, transform)\n"
      ],
      "metadata": {
        "id": "GUQO6lcGBuR6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_random_image(number_of_random_images, database_filenames, database_images, database_file_path):\n",
        "    \n",
        "    all_average_precision = []\n",
        "\n",
        "    for i_random in range(number_of_random_images):\n",
        "\n",
        "        query_image_path = random.choice(database_file_path)\n",
        "        relevant_image_folder = os.path.dirname(query_image_path)\n",
        "        query_image = Image.open(query_image_path)\n",
        "        query_image = transform(query_image)\n",
        "\n",
        "        def get_image_names_from_folder(root_folder):\n",
        "            image_extensions = ['jpg', 'png', 'gif', 'jpeg']\n",
        "            image_names = []\n",
        "\n",
        "            for ext in image_extensions:\n",
        "                image_paths = glob.glob(f'{root_folder}/**/*.{ext}', recursive=True)\n",
        "                for path in image_paths:\n",
        "                    image_name = os.path.basename(path)\n",
        "                    image_names.append(image_name)\n",
        "\n",
        "            return image_names\n",
        "\n",
        "        relevant_images = get_image_names_from_folder(relevant_image_folder)\n",
        "\n",
        "\n",
        "        \n",
        "        global_extractor = GlobalFeature(vgg16_model)\n",
        "        query_global_feature = global_extractor.extract(query_image)\n",
        "        local_extractor = LocalFeature(vgg16_model)\n",
        "        query_local_feature = global_extractor.extract(query_image)\n",
        "\n",
        "        query_features = query_global_feature + alpha * query_local_feature\n",
        "\n",
        "\n",
        "        all_similarity_score = []\n",
        "\n",
        "        for i,j in zip(database_filenames, database_images):\n",
        "            file_name = i\n",
        "            image = j\n",
        "            global_feature = global_extractor.extract(image)\n",
        "            local_feature = global_extractor.extract(image)\n",
        "            database_feature =  global_feature + alpha * local_feature\n",
        "            get_similarity = similarity_score(database_feature, query_features)\n",
        "            all_similarity_score.append(get_similarity)\n",
        "\n",
        "\n",
        "        \n",
        "        def get_top_k_indices(input_list, k):\n",
        "            return sorted(range(len(input_list)), key=lambda i: input_list[i], reverse=True)[:k]\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        top_k_indices = get_top_k_indices(all_similarity_score, k)\n",
        "\n",
        "        top_k_results_path = [database_file_path[indices]  for indices in top_k_indices]\n",
        "        top_k_results = [database_filenames[indices]  for indices in top_k_indices]\n",
        "\n",
        "        one_average_precision = average_precision(top_k_results, relevant_images)\n",
        "\n",
        "        plot_precision_recall_curve(top_k_results,relevant_images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # query image\n",
        "        print(\"\\n\")\n",
        "        print(\"Random Image Number -> \", i_random+1)\n",
        "        img = Image.open(query_image_path)\n",
        "        image_name = os.path.basename(query_image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"Query Image: {image_name}\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        print(\"Average precision for this image\", one_average_precision)\n",
        "        \n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        plot_roc_curve(top_k_results,relevant_images)\n",
        "\n",
        "        all_average_precision.append(one_average_precision)\n",
        "\n",
        "        plot_anmrr_curve(top_k_results,relevant_images)\n",
        "\n",
        "\n",
        "        # Open and display each image\n",
        "        for i in range(min(top_no_image_print, k)):\n",
        "            path = top_k_results_path[i]\n",
        "            image_name = os.path.basename(path)\n",
        "            img = Image.open(path)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f'Top {i+1} result : {image_name}')   # Add a title to the image\n",
        "            plt.show()\n",
        "            print(\"\\n\")\n",
        "\n",
        "\n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        print(\"_________________________________________________________________________________________________________________________________________\")\n",
        "        print(\"\\n\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return all_average_precision\n"
      ],
      "metadata": {
        "id": "t5aZgKs7BzEM"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\n",
        "ap = get_random_image(no_random_images,database_filenames, database_images, database_file_path )\n",
        "\n"
      ],
      "metadata": {
        "id": "3dX18O7sB1Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_ = mean_average_precision(ap)\n",
        "\n",
        "print(map_)"
      ],
      "metadata": {
        "id": "94cp2UViCbcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tEO4IJXw1q-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}